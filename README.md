# Learning: Mini GPT from Scratch

This repository is a concise guide inspired by a YouTube video lecture, where Andrej Karpathy demonstrates building a character-level language model similar to GPT from scratch.

step-by-step guide on building a simple text generation model, akin to a miniature version of GPT (Generative Pre-trained Transformer), by following along with the provided code. The key takeaways include:

- **Transformer Model**: Learn to construct a simplified Transformer model for text generation.
- **Character-Level Generation**: Predict the next character in a sequence, resembling Shakespearean text.
- **Python Implementation**: Focus on fundamental concepts with Python code.
- **Video Inspiration**: Follow along with Andrej Karpathy's lecture on building language models.
